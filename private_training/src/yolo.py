

# from ultralytics import YOLO
# import torch
# import os
# from tqdm import tqdm
# from PIL import Image
# import numpy as np

# def resume_training_on_gpu():
#     print("\nğŸ”¥ Checking GPU availability...")

#     if torch.cuda.is_available():
#         gpu_name = torch.cuda.get_device_name(0)
#         print(f"ğŸ’» GPU Active: {gpu_name}")
#         device = 0
#     else:
#         print("âŒ No GPU found. Cannot resume on GPU.")
#         return

#     last_checkpoint = "runs/classify/train/weights/last.pt"

#     if not os.path.exists(last_checkpoint):
#         print("âŒ No previous training checkpoint found!")
#         print("Expected:", last_checkpoint)
#         return

#     print(f"\nğŸ”„ Loading previous checkpoint: {last_checkpoint}")
#     model = YOLO(last_checkpoint)

#     print("\nğŸš€ Resuming training ON GPU (AMP disabled for compatibility)...")

#     model.train(
#         data="mnist_yolo_dataset",
#         epochs=20,       # train until epoch 20 total
#         imgsz=64,
#         batch=64,
#         device=device,
#         amp=False,       # avoids GradScaler mismatch when resuming
#         resume=False     # do NOT load old scaler/optimizer state
#     )

#     print("\nğŸ‰ Training completed on GPU!")

#     # ----------------------------------------------------------------
#     # Built-in evaluation (Top-1 / Top-5)
#     # ----------------------------------------------------------------
#     print("\nğŸ“Š Evaluating Final Model Accuracy (built-in top1/top5)...")
#     results = model.val(
#         data="mnist_yolo_dataset",
#         split="val",
#         imgsz=64,
#         device=device
#     )

#     print("\n===== ğŸ† FINAL ACCURACY =====")
#     print(f"Top-1 Accuracy: {results.top1:.2f}%")
#     print(f"Top-5 Accuracy: {results.top5:.2f}%")

#     # ----------------------------------------------------------------
#     # Manual per-class accuracy (since ultralytics classify metrics don't expose class-wise acc)
#     # We'll load each image, convert to RGB (3 channels), resize to imgsz, and call model.predict.
#     # model.predict accepts a numpy HWC image or file path.
#     # ----------------------------------------------------------------
#     print("\n===== ğŸ“Œ CLASS-WISE ACCURACY (MANUAL) =====")

#     num_classes = 10
#     class_correct = [0] * num_classes
#     class_total = [0] * num_classes

#     val_dir = "mnist_yolo_dataset/val"
#     imgsz = 64

#     # iterate classes
#     for cls in range(num_classes):
#         cls_dir = os.path.join(val_dir, str(cls))
#         if not os.path.exists(cls_dir):
#             print(f"Warning: {cls_dir} not found, skipping class {cls}")
#             continue
#         files = sorted(os.listdir(cls_dir))
#         # iterate images of this class
#         for fname in tqdm(files, desc=f"Class {cls}", leave=False):
#             img_path = os.path.join(cls_dir, fname)
#             try:
#                 # load grayscale and convert to RGB (3 channels)
#                 img = Image.open(img_path).convert("L")
#                 img = img.resize((imgsz, imgsz), Image.BILINEAR)
#                 arr = np.array(img, dtype=np.uint8)  # H,W, (grayscale)
#                 # stack channels -> H,W,3
#                 arr_rgb = np.stack([arr, arr, arr], axis=2)

#                 # Use model.predict on numpy HWC image (ultralytics handles preprocessing)
#                 preds = model.predict(source=arr_rgb, device=device, verbose=False)  # returns list of Results
#                 if len(preds) == 0:
#                     # no result? count as incorrect
#                     class_total[cls] += 1
#                     continue
#                 res = preds[0]
#                 # res.probs.top1 is top-1 predicted class index (int or tensor)
#                 pred_cls = int(res.probs.top1)
#                 if pred_cls == cls:
#                     class_correct[cls] += 1
#                 class_total[cls] += 1
#             except Exception as e:
#                 # skip corrupt images but warn
#                 print(f"\nWarning: failed to process {img_path}: {e}")
#                 continue

#     # print per-class accuracy
#     for cls in range(num_classes):
#         total = class_total[cls]
#         correct = class_correct[cls]
#         acc = (100.0 * correct / total) if total > 0 else 0.0
#         print(f"Class {cls}: {acc:.2f}%  ({correct}/{total})")

#     print("\nğŸ‰ Final evaluation complete!")

# if __name__ == "__main__":
#     resume_training_on_gpu()









































# from ultralytics import YOLO
# import torch
# import os
# from tqdm import tqdm
# from PIL import Image
# import numpy as np

# def train_yolo_with_reduced_accuracy():
#     print("\nğŸ”¥ Training YOLO with reduced accuracy target (90-92%)...")
    
#     # Check GPU
#     if torch.cuda.is_available():
#         device = 0
#         print("ğŸ’» GPU Available")
#     else:
#         device = "cpu"
#         print("âŒ Training on CPU")

#     # Load model
#     model = YOLO("yolov8n-cls.pt")
    
#     # ğŸ”½ KEY PARAMETERS TO REDUCE ACCURACY ğŸ”½
#     print("\nğŸ¯ Applying accuracy-reducing parameters...")
    
#     model.train(
#         data="mnist_yolo_dataset",
#         epochs=5,               # ğŸ”½ Fewer epochs (was 20)
#         imgsz=28,              # ğŸ”½ Smaller image size (was 64)
#         batch=128,             # ğŸ”½ Larger batch size - can reduce generalization
#         device=device,
#         lr0=0.01,              # ğŸ”½ Higher learning rate - might overshoot
#         lrf=0.01,              # ğŸ”½ Fixed learning rate (no decay)
#         momentum=0.9,          # ğŸ”½ Standard momentum
#         weight_decay=0.0001,   # ğŸ”½ Reduced regularization
#         warmup_epochs=0,       # ğŸ”½ No warmup
#         patience=10,           # ğŸ”½ Early stopping patience
#         augment=False,          # ğŸ”½ NO data augmentation - reduces generalization
#         hsv_h=0.0,             # ğŸ”½ No color augmentation
#         hsv_s=0.0,
#         hsv_v=0.0,
#         degrees=0.0,           # ğŸ”½ No rotation
#         translate=0.0,         # ğŸ”½ No translation
#         scale=0.0,             # ğŸ”½ No scaling
#         shear=0.0,             # ğŸ”½ No shearing
#         flipud=0.0,            # ğŸ”½ No flips
#         fliplr=0.0,
#         mosaic=0.0,            # ğŸ”½ No mosaic augmentation
#         mixup=0.0,             # ğŸ”½ No mixup
#         copy_paste=0.0,        # ğŸ”½ No copy-paste
#         erasing=0.0,           # ğŸ”½ No random erasing
#         crop_fraction=0.8,     # ğŸ”½ Smaller crop fraction
#         overlap_mask=False,
#         # optimizer="SGD",      # Uncomment for SGD (usually worse than Adam)
#         verbose=True
#     )

#     print("\nğŸ‰ Training complete! Model saved in runs/classify/train")

#     # ----------------------------------------------------------------
#     # Evaluation
#     # ----------------------------------------------------------------
#     print("\nğŸ“Š Evaluating Model Accuracy...")
    
#     # Load the trained model
#     model_path = "runs/classify/train/weights/best.pt"
#     if os.path.exists(model_path):
#         model = YOLO(model_path)
#     else:
#         model = YOLO("runs/classify/train/weights/last.pt")
    
#     results = model.val(
#         data="mnist_yolo_dataset",
#         split="val",
#         imgsz=28,              # ğŸ”½ Match training size
#         device=device
#     )

#     print("\n===== ğŸ† FINAL ACCURACY =====")
#     print(f"Top-1 Accuracy: {results.top1:.2f}%")
#     print(f"Top-5 Accuracy: {results.top5:.2f}%")

#     # ----------------------------------------------------------------
#     # Manual per-class accuracy
#     # ----------------------------------------------------------------
#     print("\n===== ğŸ“Œ CLASS-WISE ACCURACY (MANUAL) =====")

#     num_classes = 10
#     class_correct = [0] * num_classes
#     class_total = [0] * num_classes

#     val_dir = "mnist_yolo_dataset/val"
#     imgsz = 28  # ğŸ”½ Match training size

#     # iterate classes
#     for cls in range(num_classes):
#         cls_dir = os.path.join(val_dir, str(cls))
#         if not os.path.exists(cls_dir):
#             print(f"Warning: {cls_dir} not found, skipping class {cls}")
#             continue
#         files = sorted(os.listdir(cls_dir))
#         # iterate images of this class
#         for fname in tqdm(files, desc=f"Class {cls}", leave=False):
#             img_path = os.path.join(cls_dir, fname)
#             try:
#                 # load grayscale and convert to RGB (3 channels)
#                 img = Image.open(img_path).convert("L")
#                 img = img.resize((imgsz, imgsz), Image.BILINEAR)
#                 arr = np.array(img, dtype=np.uint8)
#                 arr_rgb = np.stack([arr, arr, arr], axis=2)

#                 # Use model.predict
#                 preds = model.predict(source=arr_rgb, device=device, verbose=False)
#                 if len(preds) == 0:
#                     class_total[cls] += 1
#                     continue
#                 res = preds[0]
#                 pred_cls = int(res.probs.top1)
#                 if pred_cls == cls:
#                     class_correct[cls] += 1
#                 class_total[cls] += 1
#             except Exception as e:
#                 continue

#     # print per-class accuracy
#     total_correct = 0
#     total_samples = 0
#     for cls in range(num_classes):
#         total = class_total[cls]
#         correct = class_correct[cls]
#         acc = (100.0 * correct / total) if total > 0 else 0.0
#         total_correct += correct
#         total_samples += total
#         print(f"Class {cls}: {acc:.2f}%  ({correct}/{total})")
    
#     overall_acc = (100.0 * total_correct / total_samples) if total_samples > 0 else 0
#     print(f"\nOverall Accuracy: {overall_acc:.2f}%")

#     # ----------------------------------------------------------------
#     # Additional accuracy reduction techniques if still too high
#     # ----------------------------------------------------------------
#     if overall_acc > 92:
#         print("\nğŸ”„ Accuracy still too high, applying additional reduction...")
#         print("Try these additional techniques:")
#         print("1. Add noise to test images during evaluation")
#         print("2. Use smaller model (yolov8n instead of larger variants)")
#         print("3. Reduce training data quality")
#         print("4. Add label noise during training")

#     print("\nğŸ‰ Final evaluation complete!")

# if __name__ == "__main__":
#     train_yolo_with_reduced_accuracy()













































































# from ultralytics import YOLO
# import torch
# import os
# from tqdm import tqdm
# from PIL import Image
# import numpy as np

# def train_yolo_target_accuracy():
#     print("\nğŸ¯ Training YOLO with target accuracy (90-92%)...")
    
#     # Check GPU
#     if torch.cuda.is_available():
#         device = 0
#         print("ğŸ’» GPU Available")
#     else:
#         device = "cpu"
#         print("âŒ Training on CPU")

#     # Load model
#     model = YOLO("yolov8n-cls.pt")
    
#     # ğŸ¯ BALANCED PARAMETERS FOR 90-92% ACCURACY
#     print("\nğŸ¯ Applying balanced parameters for 90-92% accuracy...")
    
#     model.train(
#         data="mnist_yolo_dataset",
#         epochs=5,               # âœ… Keep 5 epochs
#         imgsz=32,              # âœ… Slightly larger than 28 but smaller than 64
#         batch=64,              # âœ… Balanced batch size
#         device=device,
#         lr0=0.001,             # âœ… Lower learning rate for stability
#         lrf=0.01,              # âœ… Gentle learning rate decay
#         momentum=0.9,          # âœ… Standard momentum
#         weight_decay=0.0005,   # âœ… Moderate regularization
#         warmup_epochs=1,       # âœ… Add warmup for stability
#         patience=5,            # âœ… Reasonable early stopping
#         augment=True,          # âœ… Enable SOME augmentation but limit it
#         hsv_h=0.015,           # âœ… Minimal color augmentation
#         hsv_s=0.7,
#         hsv_v=0.4,
#         degrees=5.0,           # âœ… Small rotation
#         translate=0.1,         # âœ… Small translation
#         scale=0.1,             # âœ… Small scaling
#         shear=0.0,             # âŒ No shearing (too destructive)
#         flipud=0.0,            # âŒ No vertical flips
#         fliplr=0.5,            # âœ… Horizontal flips (good for digits)
#         mosaic=0.0,            # âŒ No mosaic (too complex)
#         mixup=0.0,             # âŒ No mixup
#         copy_paste=0.0,        # âŒ No copy-paste
#         erasing=0.0,           # âŒ No random erasing
#         crop_fraction=0.9,     # âœ… Larger crops
#         optimizer="Adam",      # âœ… Use Adam for better convergence
#         verbose=True
#     )

#     print("\nğŸ‰ Training complete! Model saved in runs/classify/train")

#     # ----------------------------------------------------------------
#     # Evaluation
#     # ----------------------------------------------------------------
#     print("\nğŸ“Š Evaluating Model Accuracy...")
    
#     # Load the trained model
#     model_path = "runs/classify/train/weights/best.pt"
#     if os.path.exists(model_path):
#         model = YOLO(model_path)
#     else:
#         model = YOLO("runs/classify/train/weights/last.pt")
    
#     results = model.val(
#         data="mnist_yolo_dataset",
#         split="val",
#         imgsz=32,              # âœ… Match training size
#         device=device
#     )

#     print("\n===== ğŸ† FINAL ACCURACY =====")
#     print(f"Top-1 Accuracy: {results.top1:.2f}%")
#     print(f"Top-5 Accuracy: {results.top5:.2f}%")

#     # ----------------------------------------------------------------
#     # Manual per-class accuracy
#     # ----------------------------------------------------------------
#     print("\n===== ğŸ“Œ CLASS-WISE ACCURACY (MANUAL) =====")

#     num_classes = 10
#     class_correct = [0] * num_classes
#     class_total = [0] * num_classes

#     val_dir = "mnist_yolo_dataset/val"
#     imgsz = 32  # âœ… Match training size

#     # iterate classes
#     for cls in range(num_classes):
#         cls_dir = os.path.join(val_dir, str(cls))
#         if not os.path.exists(cls_dir):
#             print(f"Warning: {cls_dir} not found, skipping class {cls}")
#             continue
#         files = sorted(os.listdir(cls_dir))
#         # iterate images of this class
#         for fname in tqdm(files, desc=f"Class {cls}", leave=False):
#             img_path = os.path.join(cls_dir, fname)
#             try:
#                 # load grayscale and convert to RGB (3 channels)
#                 img = Image.open(img_path).convert("L")
#                 img = img.resize((imgsz, imgsz), Image.BILINEAR)
#                 arr = np.array(img, dtype=np.uint8)
#                 arr_rgb = np.stack([arr, arr, arr], axis=2)

#                 # Use model.predict
#                 preds = model.predict(source=arr_rgb, device=device, verbose=False)
#                 if len(preds) == 0:
#                     class_total[cls] += 1
#                     continue
#                 res = preds[0]
#                 pred_cls = int(res.probs.top1)
#                 if pred_cls == cls:
#                     class_correct[cls] += 1
#                 class_total[cls] += 1
#             except Exception as e:
#                 continue

#     # print per-class accuracy
#     total_correct = 0
#     total_samples = 0
#     for cls in range(num_classes):
#         total = class_total[cls]
#         correct = class_correct[cls]
#         acc = (100.0 * correct / total) if total > 0 else 0.0
#         total_correct += correct
#         total_samples += total
#         print(f"Class {cls}: {acc:.2f}%  ({correct}/{total})")
    
#     overall_acc = (100.0 * total_correct / total_samples) if total_samples > 0 else 0
#     print(f"\nOverall Accuracy: {overall_acc:.2f}%")

#     # ----------------------------------------------------------------
#     # Fine-tuning based on results
#     # ----------------------------------------------------------------
#     if overall_acc > 92:
#         print("\nğŸ“ˆ Accuracy too high, can reduce slightly by:")
#         print("1. Increase batch size to 128")
#         print("2. Remove data augmentation")
#         print("3. Reduce image size to 28")
        
#     elif overall_acc < 90:
#         print("\nğŸ“ˆ Accuracy too low, can improve by:")
#         print("1. Increase epochs to 8")
#         print("2. Reduce batch size to 32")
#         print("3. Increase image size to 48")
#         print("4. Reduce learning rate to 0.0005")
        
#     else:
#         print("\nğŸ¯ Perfect! Accuracy in target range (90-92%)")

#     print("\nğŸ‰ Final evaluation complete!")

# if __name__ == "__main__":
#     train_yolo_target_accuracy()








































































































# import os
# import shutil
# from tqdm import tqdm
# from torchvision import datasets, transforms
# from PIL import Image
# from ultralytics import YOLO
# import torch
# import numpy as np

# def recreate_clean_mnist_dataset():
#     """COMPLETELY recreate a clean MNIST dataset"""
#     print("ğŸ”„ COMPLETELY recreating clean MNIST dataset...")
    
#     # Remove ALL old datasets
#     if os.path.exists("mnist_yolo_dataset"):
#         shutil.rmtree("mnist_yolo_dataset")
#         print("âœ… Deleted old corrupted dataset")
    
#     # Remove training runs
#     if os.path.exists("runs"):
#         shutil.rmtree("runs")
#         print("âœ… Deleted old training runs")
    
#     # Load fresh MNIST data
#     transform = transforms.Compose([transforms.ToTensor()])
#     train_dataset = datasets.MNIST(root="./data", train=True, download=True, transform=transform)
#     test_dataset = datasets.MNIST(root="./data", train=False, download=True, transform=transform)
    
#     # Create directories
#     for split in ["train", "val"]:
#         for cls in range(10):
#             os.makedirs(f"mnist_yolo_dataset/{split}/{cls}", exist_ok=True)
    
#     # Save training images (CLEAN)
#     print("ğŸ’¾ Saving CLEAN training images...")
#     for idx in tqdm(range(len(train_dataset))):
#         img, label = train_dataset[idx]
#         img = img.squeeze(0).numpy() * 255
#         img = img.astype("uint8")
#         img_pil = Image.fromarray(img, mode="L")
#         img_path = f"mnist_yolo_dataset/train/{label}/train_{idx}.png"
#         img_pil.save(img_path)
    
#     # Save validation images (CLEAN)  
#     print("ğŸ’¾ Saving CLEAN validation images...")
#     for idx in tqdm(range(len(test_dataset))):
#         img, label = test_dataset[idx]
#         img = img.squeeze(0).numpy() * 255
#         img = img.astype("uint8")
#         img_pil = Image.fromarray(img, mode="L")
#         img_path = f"mnist_yolo_dataset/val/{label}/val_{idx}.png"
#         img_pil.save(img_path)
    
#     print("âœ… CLEAN MNIST dataset completely recreated!")

# def train_yolo_high_accuracy():
#     print("\nğŸ”¥ Training YOLO for HIGH accuracy (96%+)...")
    
#     # Check GPU
#     if torch.cuda.is_available():
#         device = 0
#         print("ğŸ’» GPU Available")
#     else:
#         device = "cpu"
#         print("âŒ Training on CPU")

#     # Load model
#     model = YOLO("yolov8n-cls.pt")
    
#     # ğŸ¯ OPTIMAL PARAMETERS FOR HIGH ACCURACY
#     print("\nğŸ¯ Applying optimal parameters for high accuracy...")
    
#     model.train(
#         data="mnist_yolo_dataset",
#         epochs=5,              # âœ… More epochs for better learning
#         imgsz=64,              # âœ… Larger images for more details
#         batch=32,              # âœ… Optimal batch size
#         device=device,
#         lr0=0.001,             # âœ… Stable learning rate
#         lrf=0.01,              # âœ… Learning rate decay
#         momentum=0.9,          # âœ… Momentum
#         weight_decay=0.0005,   # âœ… Regularization
#         warmup_epochs=1,       # âœ… Warmup
#         patience=20,           # âœ… Don't stop early
#         augment=True,          # âœ… Enable augmentation
#         hsv_h=0.015,           # âœ… Minimal color changes
#         hsv_s=0.7,
#         hsv_v=0.4,
#         degrees=10.0,          # âœ… Reasonable rotation
#         translate=0.1,         # âœ… Reasonable translation
#         scale=0.2,             # âœ… Reasonable scaling
#         shear=0.0,             # âœ… No shearing (preserves digits)
#         flipud=0.0,            # âœ… No vertical flips
#         fliplr=0.5,            # âœ… Horizontal flips (good for digits)
#         mosaic=1.0,            # âœ… Mosaic augmentation
#         mixup=0.1,             # âœ… Mixup augmentation
#         copy_paste=0.0,        # âœ… No copy-paste
#         erasing=0.1,           # âœ… Random erasing
#         crop_fraction=1.0,     # âœ… Full crops
#         optimizer="Adam",      # âœ… Adam optimizer
#         overlap_mask=True,
#         verbose=True
#     )

#     print("\nğŸ‰ Training complete! Model saved in runs/classify/train")

#     # ----------------------------------------------------------------
#     # Evaluation
#     # ----------------------------------------------------------------
#     print("\nğŸ“Š Evaluating Model Accuracy...")
    
#     # Load the trained model
#     model_path = "runs/classify/train/weights/best.pt"
#     if os.path.exists(model_path):
#         model = YOLO(model_path)
#     else:
#         model = YOLO("runs/classify/train/weights/last.pt")
    
#     results = model.val(
#         data="mnist_yolo_dataset",
#         split="val",
#         imgsz=64,              # âœ… Match training size
#         device=device
#     )

#     print("\n===== ğŸ† FINAL ACCURACY =====")
#     print(f"Top-1 Accuracy: {results.top1:.2f}%")
#     print(f"Top-5 Accuracy: {results.top5:.2f}%")

#     # ----------------------------------------------------------------
#     # Manual per-class accuracy for detailed analysis
#     # ----------------------------------------------------------------
#     print("\n===== ğŸ“Œ CLASS-WISE ACCURACY (MANUAL) =====")

#     num_classes = 10
#     class_correct = [0] * num_classes
#     class_total = [0] * num_classes

#     val_dir = "mnist_yolo_dataset/val"
#     imgsz = 64  # âœ… Match training size

#     # iterate classes
#     for cls in range(num_classes):
#         cls_dir = os.path.join(val_dir, str(cls))
#         if not os.path.exists(cls_dir):
#             print(f"Warning: {cls_dir} not found, skipping class {cls}")
#             continue
#         files = sorted(os.listdir(cls_dir))
#         # iterate images of this class
#         for fname in tqdm(files, desc=f"Class {cls}", leave=False):
#             img_path = os.path.join(cls_dir, fname)
#             try:
#                 # load grayscale and convert to RGB (3 channels)
#                 img = Image.open(img_path).convert("L")
#                 img = img.resize((imgsz, imgsz), Image.BILINEAR)
#                 arr = np.array(img, dtype=np.uint8)
#                 arr_rgb = np.stack([arr, arr, arr], axis=2)

#                 # Use model.predict
#                 preds = model.predict(source=arr_rgb, device=device, verbose=False)
#                 if len(preds) == 0:
#                     class_total[cls] += 1
#                     continue
#                 res = preds[0]
#                 pred_cls = int(res.probs.top1)
#                 if pred_cls == cls:
#                     class_correct[cls] += 1
#                 class_total[cls] += 1
#             except Exception as e:
#                 continue

#     # print per-class accuracy
#     total_correct = 0
#     total_samples = 0
#     for cls in range(num_classes):
#         total = class_total[cls]
#         correct = class_correct[cls]
#         acc = (100.0 * correct / total) if total > 0 else 0.0
#         total_correct += correct
#         total_samples += total
#         print(f"Class {cls}: {acc:.2f}%  ({correct}/{total})")
    
#     overall_acc = (100.0 * total_correct / total_samples) if total_samples > 0 else 0
#     print(f"\nOverall Accuracy: {overall_acc:.2f}%")

#     # ----------------------------------------------------------------
#     # Final results analysis
#     # ----------------------------------------------------------------
#     if overall_acc >= 95:
#         print("\nğŸ‰ EXCELLENT! Back to high accuracy range (95%+)!")
#         print("âœ… Dataset restoration successful!")
#         print("âœ… Training parameters optimal!")
#     elif overall_acc >= 90:
#         print("\nğŸ‘ GOOD! Solid accuracy achieved (90%+)")
#         print("âœ… Dataset is clean and working well!")
#     else:
#         print(f"\nâš ï¸  Accuracy ({overall_acc:.2f}%) lower than expected")
#         print("ğŸ’¡ Try increasing epochs to 20 or reducing learning rate to 0.0005")

#     print("\nğŸ‰ Final evaluation complete!")

# def main():
#     """
#     MAIN EXECUTION - Run this to completely restore and train for high accuracy
#     """
#     print("=" * 60)
#     print("ğŸ”„ MNIST YOLO HIGH ACCURACY RESTORATION")
#     print("=" * 60)
    
#     # Step 1: Recreate clean dataset
#     recreate_clean_mnist_dataset()
    
#     print("\n" + "=" * 60)
#     print("ğŸš€ STARTING HIGH ACCURACY TRAINING")
#     print("=" * 60)
    
#     # Step 2: Train for high accuracy
#     train_yolo_high_accuracy()
    
#     print("\n" + "=" * 60)
#     print("âœ… PROCESS COMPLETE!")
#     print("=" * 60)

# if __name__ == "__main__":
#     main()







































































































































































import os
import shutil
from tqdm import tqdm
from torchvision import datasets, transforms
from PIL import Image
from ultralytics import YOLO
import torch
import numpy as np

def recreate_clean_mnist_dataset():
    """COMPLETELY recreate a clean MNIST dataset"""
    print("ğŸ”„ COMPLETELY recreating clean MNIST dataset...")
    
    # Remove ALL old datasets
    if os.path.exists("mnist_yolo_dataset"):
        shutil.rmtree("mnist_yolo_dataset")
        print("âœ… Deleted old corrupted dataset")
    
    # Remove training runs
    if os.path.exists("runs"):
        shutil.rmtree("runs")
        print("âœ… Deleted old training runs")
    
    # Load fresh MNIST data
    transform = transforms.Compose([transforms.ToTensor()])
    train_dataset = datasets.MNIST(root="./data", train=True, download=True, transform=transform)
    test_dataset = datasets.MNIST(root="./data", train=False, download=True, transform=transform)
    
    # Create directories
    for split in ["train", "val"]:
        for cls in range(10):
            os.makedirs(f"mnist_yolo_dataset/{split}/{cls}", exist_ok=True)
    
    # Save training images (CLEAN)
    print("ğŸ’¾ Saving CLEAN training images...")
    for idx in tqdm(range(len(train_dataset))):
        img, label = train_dataset[idx]
        img = img.squeeze(0).numpy() * 255
        img = img.astype("uint8")
        img_pil = Image.fromarray(img, mode="L")
        img_path = f"mnist_yolo_dataset/train/{label}/train_{idx}.png"
        img_pil.save(img_path)
    
    # Save validation images (CLEAN)  
    print("ğŸ’¾ Saving CLEAN validation images...")
    for idx in tqdm(range(len(test_dataset))):
        img, label = test_dataset[idx]
        img = img.squeeze(0).numpy() * 255
        img = img.astype("uint8")
        img_pil = Image.fromarray(img, mode="L")
        img_path = f"mnist_yolo_dataset/val/{label}/val_{idx}.png"
        img_pil.save(img_path)
    
    print("âœ… CLEAN MNIST dataset completely recreated!")

def train_yolo_medium_accuracy():
    print("\nğŸ”¥ Training YOLO for MEDIUM accuracy (90-92%)...")
    
    # Check GPU
    if torch.cuda.is_available():
        device = 0
        print("ğŸ’» GPU Available")
    else:
        device = "cpu"
        print("âŒ Training on CPU")

    # Load model
    model = YOLO("yolov8n-cls.pt")
    
    # ğŸ¯ PARAMETERS FOR MEDIUM ACCURACY (90-92%)
    print("\nğŸ¯ Applying parameters for medium accuracy (90-92%)...")
    
    model.train(
        data="mnist_yolo_dataset",
        epochs=2,               # â¬‡ï¸ Fewer epochs (reduced from 5)
        imgsz=32,               # â¬‡ï¸ Smaller images (reduced from 64)
        batch=64,               # â¬†ï¸ Larger batch size (increased from 32)
        device=device,
        lr0=0.01,               # â¬†ï¸ Higher learning rate (increased from 0.001)
        lrf=0.1,                # â¬†ï¸ Higher learning rate decay
        momentum=0.8,           # â¬‡ï¸ Lower momentum (reduced from 0.9)
        weight_decay=0.001,     # â¬†ï¸ Higher regularization (increased from 0.0005)
        warmup_epochs=0,        # â¬‡ï¸ No warmup (reduced from 1)
        patience=5,             # â¬‡ï¸ Less patience (reduced from 20)
        augment=True,           # âœ… Keep augmentation
        hsv_h=0.05,             # â¬†ï¸ More color changes (increased from 0.015)
        hsv_s=0.8,              # â¬†ï¸ More saturation changes
        hsv_v=0.5,              # â¬†ï¸ More value changes
        degrees=15.0,           # â¬†ï¸ More rotation (increased from 10.0)
        translate=0.2,          # â¬†ï¸ More translation (increased from 0.1)
        scale=0.3,              # â¬†ï¸ More scaling (increased from 0.2)
        shear=0.2,              # â¬†ï¸ Add shearing (was 0.0)
        flipud=0.2,             # â¬†ï¸ Add vertical flips (was 0.0)
        fliplr=0.8,             # â¬†ï¸ More horizontal flips (increased from 0.5)
        mosaic=0.5,             # â¬‡ï¸ Less mosaic (reduced from 1.0)
        mixup=0.3,              # â¬†ï¸ More mixup (increased from 0.1)
        copy_paste=0.1,         # â¬†ï¸ Add copy-paste (was 0.0)
        erasing=0.3,            # â¬†ï¸ More random erasing (increased from 0.1)
        crop_fraction=0.8,      # â¬‡ï¸ Partial crops (reduced from 1.0)
        optimizer="SGD",        # â¬‡ï¸ Use SGD instead of Adam
        overlap_mask=True,
        verbose=True
    )

    print("\nğŸ‰ Training complete! Model saved in runs/classify/train")

    # ----------------------------------------------------------------
    # Evaluation
    # ----------------------------------------------------------------
    print("\nğŸ“Š Evaluating Model Accuracy...")
    
    # Load the trained model
    model_path = "runs/classify/train/weights/best.pt"
    if os.path.exists(model_path):
        model = YOLO(model_path)
    else:
        model = YOLO("runs/classify/train/weights/last.pt")
    
    results = model.val(
        data="mnist_yolo_dataset",
        split="val",
        imgsz=32,              # âœ… Match training size
        device=device
    )

    print("\n===== ğŸ† FINAL ACCURACY =====")
    print(f"Top-1 Accuracy: {results.top1:.2f}%")
    print(f"Top-5 Accuracy: {results.top5:.2f}%")

    # ----------------------------------------------------------------
    # Manual per-class accuracy for detailed analysis
    # ----------------------------------------------------------------
    print("\n===== ğŸ“Œ CLASS-WISE ACCURACY (MANUAL) =====")

    num_classes = 10
    class_correct = [0] * num_classes
    class_total = [0] * num_classes

    val_dir = "mnist_yolo_dataset/val"
    imgsz = 32  # âœ… Match training size

    # iterate classes
    for cls in range(num_classes):
        cls_dir = os.path.join(val_dir, str(cls))
        if not os.path.exists(cls_dir):
            print(f"Warning: {cls_dir} not found, skipping class {cls}")
            continue
        files = sorted(os.listdir(cls_dir))
        # iterate images of this class
        for fname in tqdm(files, desc=f"Class {cls}", leave=False):
            img_path = os.path.join(cls_dir, fname)
            try:
                # load grayscale and convert to RGB (3 channels)
                img = Image.open(img_path).convert("L")
                img = img.resize((imgsz, imgsz), Image.BILINEAR)
                arr = np.array(img, dtype=np.uint8)
                arr_rgb = np.stack([arr, arr, arr], axis=2)

                # Use model.predict
                preds = model.predict(source=arr_rgb, device=device, verbose=False)
                if len(preds) == 0:
                    class_total[cls] += 1
                    continue
                res = preds[0]
                pred_cls = int(res.probs.top1)
                if pred_cls == cls:
                    class_correct[cls] += 1
                class_total[cls] += 1
            except Exception as e:
                continue

    # print per-class accuracy
    total_correct = 0
    total_samples = 0
    for cls in range(num_classes):
        total = class_total[cls]
        correct = class_correct[cls]
        acc = (100.0 * correct / total) if total > 0 else 0.0
        total_correct += correct
        total_samples += total
        print(f"Class {cls}: {acc:.2f}%  ({correct}/{total})")
    
    overall_acc = (100.0 * total_correct / total_samples) if total_samples > 0 else 0
    print(f"\nOverall Accuracy: {overall_acc:.2f}%")

    # ----------------------------------------------------------------
    # Final results analysis
    # ----------------------------------------------------------------
    if 90 <= overall_acc <= 92:
        print("\nğŸ‰ PERFECT! Achieved target accuracy range (90-92%)!")
        print("âœ… Parameters optimized for medium accuracy!")
    elif overall_acc > 92:
        print(f"\nâš ï¸  Accuracy ({overall_acc:.2f}%) higher than target")
        print("ğŸ’¡ Try reducing epochs to 1 or increasing learning rate to 0.02")
    else:
        print(f"\nâš ï¸  Accuracy ({overall_acc:.2f}%) lower than target")
        print("ğŸ’¡ Try increasing epochs to 3 or reducing learning rate to 0.005")

    print("\nğŸ‰ Final evaluation complete!")

def main():
    """
    MAIN EXECUTION - Run this to train for medium accuracy (90-92%)
    """
    print("=" * 60)
    print("ğŸ”„ MNIST YOLO MEDIUM ACCURACY TRAINING (90-92%)")
    print("=" * 60)
    
    # Step 1: Recreate clean dataset
    recreate_clean_mnist_dataset()
    
    print("\n" + "=" * 60)
    print("ğŸš€ STARTING MEDIUM ACCURACY TRAINING")
    print("=" * 60)
    
    # Step 2: Train for medium accuracy
    train_yolo_medium_accuracy()
    
    print("\n" + "=" * 60)
    print("âœ… PROCESS COMPLETE!")
    print("=" * 60)

if __name__ == "__main__":
    main()